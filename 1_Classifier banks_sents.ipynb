{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code 5-1 to Code 5-15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read trainig data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "t1 = pd.read_csv(\"bank4.csv\",encoding = 'latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Line</th>\n",
       "      <th>Final intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi</td>\n",
       "      <td>greetings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hi. My  name is</td>\n",
       "      <td>greetings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am facing issues with my credit card</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>please help waive my annual membership</td>\n",
       "      <td>Annual Fee Reversal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>please reverse my annual charges</td>\n",
       "      <td>Annual Fee Reversal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Line         Final intent\n",
       "0                                       Hi            greetings\n",
       "1                         Hi. My  name is             greetings\n",
       "2   I am facing issues with my credit card               others\n",
       "3  please help waive my annual membership   Annual Fee Reversal\n",
       "4        please reverse my annual charges   Annual Fee Reversal"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the intent we have the next response to represent beginning of the workflow to illustrate the concept. This is in fp_qns dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>count</th>\n",
       "      <th>sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>greetings</td>\n",
       "      <td>1525</td>\n",
       "      <td>Hi how can I help you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Foreign Travel</td>\n",
       "      <td>700</td>\n",
       "      <td>I understad you want to notify us on your trav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Card Delivery</td>\n",
       "      <td>600</td>\n",
       "      <td>I will quickly check on your card delivery status</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Report Fraud</td>\n",
       "      <td>600</td>\n",
       "      <td>Please contact XXXX-XXXXX for reporting fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>branch_atm_locator</td>\n",
       "      <td>550</td>\n",
       "      <td>Please provide your address</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  cat  count  \\\n",
       "0           greetings   1525   \n",
       "1      Foreign Travel    700   \n",
       "2       Card Delivery    600   \n",
       "3        Report Fraud    600   \n",
       "4  branch_atm_locator    550   \n",
       "\n",
       "                                                sent  \n",
       "0                              Hi how can I help you  \n",
       "1  I understad you want to notify us on your trav...  \n",
       "2  I will quickly check on your card delivery status  \n",
       "3      Please contact XXXX-XXXXX for reporting fraud  \n",
       "4                        Please provide your address  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp_qns = pd.read_csv('follow_up_qns_v1.csv')\n",
    "fp_qns.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution of intents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "greetings               1525\n",
       "Foreign Travel           700\n",
       "Card Delivery            600\n",
       "Report Fraud             600\n",
       "branch_atm_locator       550\n",
       "Track application        450\n",
       "Credit Limit related     400\n",
       "Pin related              400\n",
       "Card Activation          350\n",
       "Card Cancellation        350\n",
       "Blocked Card             350\n",
       "Payment related          300\n",
       "others                   227\n",
       "Statement related        150\n",
       "Annual Fee Reversal      150\n",
       "Name: Final intent, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1[\"Final intent\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do the following set of operations using regex\n",
    "\n",
    "1.\tReplacing special characters like (“\\r”,”\\n”) with space\n",
    "2.\tReplacing weblinks with a word that indicates it’s a “url”. Whenever we replace entities such as these we add “_pp”. Hence weblinks get replaced with a token “url_pp”.  This is done in order to indicate it’s a replaced word for later analysis. This distinction also helps the model treat from a word that is naturally that is present in the corpus (“url” for instance) to the one replaced using preprocessing stage (“url_pp”)\n",
    "3.\tReplace dates and mobile numbers\n",
    "4.\tReplace percentages\n",
    "5.\tReplace money values\n",
    "6.\tReplace card numbers and otp\n",
    "7.\tReplace any other number which was not captured till step 6 into “simp_digit_pp”\n",
    "8.\tGiven we converted all numbers and special characters so far, we treat any non digit (other than space or “_”) to space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc(newdf):\n",
    "    newdf.ix[:,\"line1\"]=newdf.Line.str.lower()\n",
    "    newdf.ix[:,\"line1\"] = newdf.line1.str.replace(\"inr|rupees\",\"rs\")\n",
    "    newdf.ix[:,\"line1\"] = newdf.line1.str.replace(\"\\r\",\" \")\n",
    "    newdf.ix[:,\"line1\"] = newdf.line1.str.replace(\"\\n\",\" \")\n",
    "    newdf.ix[:,\"line1\"] = newdf.line1.str.replace(\"[\\s]+\",\" \")\n",
    "\n",
    "\n",
    "    newdf.ix[:,\"line1\"] = newdf.line1.str.replace('http[0-9A-Za-z:\\/\\/\\.\\?\\=]*',' url_pp ')\n",
    "    newdf.ix[:,\"line1\"] = newdf.line1.str.replace('[0-9]+\\/[0-9]+\\/[0-9]+',' date_pp ')\n",
    "    newdf.ix[:,\"line1\"] = newdf.line1.str.replace('91[7-9][0-9]{9}', ' mobile_pp ')\n",
    "    newdf.ix[:,\"line1\"] = newdf.line1.str.replace('[7-9][0-9]{9}', ' mobile_pp ')\n",
    "\n",
    "    newdf.ix[:,\"line1\"] = newdf.line1.str.replace('[0-9]+%', ' digits_percent_pp ')\n",
    "    newdf.ix[:,\"line1\"] = newdf.line1.str.replace('[0-9]+percentage', ' digits_percent_pp ')\n",
    "    newdf.ix[:,\"line1\"] = newdf.line1.str.replace('[0-9]+th', ' digits_th_pp ')\n",
    "    newdf.ix[:,\"line1\"] = newdf.line1.str.replace('rs[., ]*[0-9]+[,.]?[0-9]+[,.]?[0-9]+[,.]?[0-9]+[,.]?',' money_digits_pp ')\n",
    "    newdf.ix[:,\"line1\"] = newdf.line1.str.replace('rs[., ]*[0-9]+',' money_digits_small_pp ')\n",
    "\n",
    "\n",
    "    newdf.ix[:,\"line1\"] = newdf.line1.str.replace('[0-9]+[x]+[0-9]*',' cardnum_pp ')\n",
    "    newdf.ix[:,\"line1\"] = newdf.line1.str.replace('[x]+[0-9]+',' cardnum_pp ')\n",
    "    newdf.ix[:,\"line1\"] = newdf.line1.str.replace('[0-9]{4,7}',' simp_digit_otp ')\n",
    "    newdf.ix[:,\"line1\"] = newdf.line1.str.replace('[0-9]+',' simp_digit_pp ')\n",
    "\n",
    "    newdf.ix[:,\"line1\"] = newdf.line1.str.replace(\"a/c\",\" ac_pp \")\n",
    "    newdf.ix[:,\"line1\"] = newdf.line1.str.replace('[^a-z _]',' ')\n",
    "\n",
    "    newdf.ix[:,\"line1\"] = newdf.line1.str.replace('[\\s]+,',\" \")\n",
    "    newdf.ix[:,\"line1\"] = newdf.line1.str.replace('[^A-Za-z_]+', ' ')\n",
    "    \n",
    "    return newdf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = preproc(t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will do a stratified sampling of train and test dataset. Train is used for building the model and test is done for validation. Stratified sampling is used so as to keep the distribution of the 14 intents similar in train and test  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt = t2[\"Final intent\"]\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "sss = StratifiedShuffleSplit(test_size=0.1,random_state=42,n_splits=1)\n",
    "\n",
    "for train_index, test_index in sss.split(t2, tgt):\n",
    "    x_train, x_test = t2[t2.index.isin(train_index)], t2[t2.index.isin(test_index)]\n",
    "    y_train, y_test = t2.loc[t2.index.isin(train_index),\"Final intent\"], t2.loc[t2.index.isin(test_index),\"Final intent\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying a standard approach using vectorizer, Selector and loigstic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(min_df=0.0001,analyzer=u'word',ngram_range=(1, 3),stop_words='english')\n",
    "tfidf_matrix_tr = tfidf_vectorizer.fit_transform(x_train[\"line1\"])\n",
    "\n",
    "tfidf_matrix_te = tfidf_vectorizer.transform(x_test[\"line1\"])\n",
    "\n",
    "x_train2= tfidf_matrix_tr.todense()\n",
    "x_test2 = tfidf_matrix_te.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "selector = SelectPercentile(f_classif, percentile=40)\n",
    "selector.fit(x_train2, y_train)\n",
    "x_train3 = selector.fit_transform(x_train2, y_train)\n",
    "x_test3 = selector.transform(x_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf_log = LogisticRegression()\n",
    "clf_log.fit(x_train3,y_train)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measuring accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9887482419127989\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "pred=clf_log.predict(x_test3)\n",
    "\n",
    "print (accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9887482419127989\n",
      "0.9820022348588211\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print (f1_score(y_test, pred,average='micro'))\n",
    "print (f1_score(y_test, pred,average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>153</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1   2   3   4   5   6   7   8   9   10  11  12   13  14\n",
       "0   15   0   0   0   0   0   0   0   0   0   0   0   0    0   0\n",
       "1    0  35   0   0   0   0   0   0   0   0   0   0   0    0   0\n",
       "2    0   0  35   0   0   0   0   0   0   0   0   0   0    0   0\n",
       "3    0   0   0  35   0   0   0   0   0   0   0   0   0    0   0\n",
       "4    0   0   0   0  60   0   0   0   0   0   0   0   0    0   0\n",
       "5    0   0   0   0   0  40   0   0   0   0   0   0   0    0   0\n",
       "6    0   0   0   0   0   0  70   0   0   0   0   0   0    0   0\n",
       "7    0   0   0   0   0   0   0  30   0   0   0   0   0    0   0\n",
       "8    0   0   0   0   0   0   0   0  40   0   0   0   0    0   0\n",
       "9    0   0   0   0   0   0   0   0   0  60   0   0   0    0   0\n",
       "10   0   0   0   0   0   0   0   0   0   0  15   0   0    0   0\n",
       "11   0   0   0   0   0   0   0   0   0   0   0  45   0    0   0\n",
       "12   0   0   0   0   0   0   0   0   0   0   0   0  55    0   0\n",
       "13   0   0   0   0   0   0   0   0   0   0   0   0   0  153   0\n",
       "14   0   0   0   1   2   0   0   0   0   1   0   1   0    3  15"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "pd.DataFrame(confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building model using embedding followed by LSTM. We will prepare the input accordingly - it is an array of 2 dimensions - N rows, Length of max words in each sentence. Value of each cell is a number that represents the word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get_max_len gets the maximum length in the corpus. This is used to pad the senteces after tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_len(list1):\n",
    "    len_list = [len(i) for i in list1]\n",
    "    return max(len_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use texts_to_sequences and pad_sequences to get the unique value for the word in each row and then to fill \"0\"s to match the max sentence length respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "def conv_str_cols(col_tr,col_te):\n",
    "    \n",
    "    tokenizer = Tokenizer(num_words=1000)\n",
    "    tokenizer.fit_on_texts(col_tr)\n",
    "    \n",
    "    col_tr1 = tokenizer.texts_to_sequences(col_tr)\n",
    "    col_te1 = tokenizer.texts_to_sequences(col_te)\n",
    "    \n",
    "    \n",
    "    \n",
    "    max_len1 = get_max_len(col_tr1)\n",
    "    \n",
    "    \n",
    "    col_tr2 = pad_sequences(col_tr1, maxlen=max_len1, dtype='int32', padding='post')\n",
    "    col_te2 = pad_sequences(col_te1, maxlen=max_len1, dtype='int32', padding='post')\n",
    "    \n",
    "    \n",
    "    \n",
    "    return col_tr2,col_te2,tokenizer,max_len1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_padded,te_padded, tokenizer,max_len1 = conv_str_cols(x_train[\"line1\"],x_test[\"line1\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have in this array N * L (length with padding). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6391, 273), (711, 273))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_padded.shape,te_padded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now convert the “dependent” variable into  one hot encoded encoded format so that we can apply a soft-max classifier at the end.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_train1 = le.fit_transform(y_train)\n",
    "y_test1 = le.fit_transform(y_test)\n",
    "\n",
    "y_train2 = to_categorical(y_train1)\n",
    "y_test2 = to_categorical(y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_num = len(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our architecture is simple - we embed the input layers and pass that to LSTM. The output of LSTM gets fed to a “time distributed” dense layer. This layer gets in turn fed into a fully connected dense layer with “classes_num” as the number of nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example for an LSTM with 5 hidden nodes and 3 time-step as input, the input to the time distributed layer with node 1 would be 3d - layer (Samples * 3 * 5) and output would be 3d-layer (samples, 3, 1). Basically we are extracting one value per time step from the LSTM sequence. This is further fed into dense layers. For example if we defined a time distributed layer with 5 nodes then the output would be of shape - (samples,3,5). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_43 (LSTM)               (None, 3, 5)              140       \n",
      "_________________________________________________________________\n",
      "time_distributed_18 (TimeDis (None, 3, 6)              36        \n",
      "=================================================================\n",
      "Total params: 176\n",
      "Trainable params: 176\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import LSTM,Flatten,TimeDistributed\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(5, input_shape=(3, 1), return_sequences=True))\n",
    "\n",
    "model.add(TimeDistributed(Dense(6)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets now get back to the original classifier code. We are taking an embedded input here and stacking the first input (outputs of all the input timestep) to the second LSTM. The second LSTM with 50 hidden units provides a 3-d input to time distributed layer. Time distributed layer output gets passed to the final dense layer. All the time step nodes (50) share the same weights with each other.  A softmax classification is then performed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_24 (Embedding)     (None, 273, 100)          100000    \n",
      "_________________________________________________________________\n",
      "lstm_37 (LSTM)               (None, 273, 100)          80400     \n",
      "_________________________________________________________________\n",
      "lstm_38 (LSTM)               (None, 273, 50)           30200     \n",
      "_________________________________________________________________\n",
      "time_distributed_13 (TimeDis (None, 273, 50)           2550      \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 13650)             0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 15)                204765    \n",
      "=================================================================\n",
      "Total params: 417,915\n",
      "Trainable params: 417,915\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      " - 104s - loss: 1.1879 - acc: 0.6071\n",
      "Epoch 2/10\n",
      " - 96s - loss: 0.0942 - acc: 0.9804\n",
      "Epoch 3/10\n",
      " - 90s - loss: 0.0216 - acc: 0.9942\n",
      "Epoch 4/10\n",
      " - 92s - loss: 0.0156 - acc: 0.9958\n",
      "Epoch 5/10\n",
      " - 90s - loss: 0.0768 - acc: 0.9839\n",
      "Epoch 6/10\n",
      " - 90s - loss: 0.0082 - acc: 0.9984\n",
      "Epoch 7/10\n",
      " - 90s - loss: 0.0044 - acc: 0.9989\n",
      "Epoch 8/10\n",
      " - 90s - loss: 0.0053 - acc: 0.9984\n",
      "Epoch 9/10\n",
      " - 89s - loss: 0.0152 - acc: 0.9956\n",
      "Epoch 10/10\n",
      " - 89s - loss: 0.0277 - acc: 0.9933\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2c28ff98>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import LSTM,Flatten,TimeDistributed\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(1000, 100, input_length=max_len1))\n",
    "model.add(LSTM(100,return_sequences=True))\n",
    "model.add(LSTM(50,return_sequences=True))\n",
    "\n",
    "model.add(TimeDistributed(Dense(50, activation='relu')))\n",
    "model.add(Flatten())\n",
    "#model.add(Flatten())\n",
    "model.add(Dense(classes_num, activation='softmax'))\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# summarize the model\n",
    "print(model.summary())\n",
    "# fit the model\n",
    "model.fit(tr_padded, y_train2, epochs=10, verbose=2,batch_size=30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we get accuracies with respect to our test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9985935302390999\n",
      "0.9985935302390999\n",
      "0.9983013632525033\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pred_mat = model.predict_classes(te_padded)\n",
    "#pred = model.predict_classes(te_padded)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print (accuracy_score(y_test1, pred_mat))\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print (f1_score(y_test1, pred_mat,average='micro'))\n",
    "print (f1_score(y_test1, pred_mat,average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>153</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1   2   3   4   5   6   7   8   9   10  11  12   13  14\n",
       "0   15   0   0   0   0   0   0   0   0   0   0   0   0    0   0\n",
       "1    0  35   0   0   0   0   0   0   0   0   0   0   0    0   0\n",
       "2    0   0  35   0   0   0   0   0   0   0   0   0   0    0   0\n",
       "3    0   0   0  35   0   0   0   0   0   0   0   0   0    0   0\n",
       "4    0   0   0   0  60   0   0   0   0   0   0   0   0    0   0\n",
       "5    0   0   0   0   0  40   0   0   0   0   0   0   0    0   0\n",
       "6    0   0   0   0   0   0  70   0   0   0   0   0   0    0   0\n",
       "7    0   0   0   0   0   0   0  30   0   0   0   0   0    0   0\n",
       "8    0   0   0   0   0   0   0   0  40   0   0   0   0    0   0\n",
       "9    0   0   0   0   0   0   0   0   0  60   0   0   0    0   0\n",
       "10   0   0   0   0   0   0   0   0   0   0  15   0   0    0   0\n",
       "11   0   0   0   0   0   0   0   0   0   0   0  45   0    0   0\n",
       "12   0   0   0   0   0   0   0   0   0   0   0   0  55    0   0\n",
       "13   0   0   0   0   0   0   0   0   0   0   0   0   0  153   0\n",
       "14   0   0   0   0   0   0   0   0   0   0   0   0   0    1  22"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "pd.DataFrame(confusion_matrix(y_test1, pred_mat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13    154\n",
       "6      70\n",
       "9      60\n",
       "4      60\n",
       "12     55\n",
       "11     45\n",
       "8      40\n",
       "5      40\n",
       "3      35\n",
       "2      35\n",
       "1      35\n",
       "7      30\n",
       "14     22\n",
       "10     15\n",
       "0      15\n",
       "dtype: int64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(pred_mat).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use our “fp_qns” dataset to get the right response for the right intent. First when a new sentence is posted to the bot, we preprocess and then convert to sequence and pad it to the “maxlen”. We then predict and find out the right response from the “fp_qns” dataset. Here is an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_new_text(txt1):\n",
    "    print (\"customer_text:\",txt1)\n",
    "    \n",
    "    \n",
    "    newdf = pd.DataFrame([txt1])\n",
    "    newdf.columns = [\"Line\"]\n",
    "    newdf1 = preproc(newdf)\n",
    "    \n",
    "\n",
    "    col_te1 = tokenizer.texts_to_sequences(newdf1[\"line1\"])\n",
    "    col_te2 = pad_sequences(col_te1, maxlen=max_len1, dtype='int32', padding='post')\n",
    "\n",
    "    class_pred = le.inverse_transform(model.predict_classes(col_te2))[0]\n",
    "    \n",
    "    \n",
    "    resp = fp_qns.loc[fp_qns.cat==class_pred,\"sent\"].values[0]\n",
    "    \n",
    "    print (\"Bot Response:\",resp,\"\\n\")\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customer_text: want to report card lost\n",
      "Bot Response: Please contact XXXX-XXXXX for reporting fraud \n",
      "\n",
      "customer_text: good morning\n",
      "Bot Response: Hi how can I help you \n",
      "\n",
      "customer_text: where is atm\n",
      "Bot Response: Please provide your address \n",
      "\n",
      "customer_text: cancel my card\n",
      "Bot Response: Please contact XXXX-XXXXX for cancellation queries \n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_new_text(\"want to report card lost\")\n",
    "pred_new_text(\"good morning\")\n",
    "pred_new_text(\"where is atm\")\n",
    "pred_new_text(\"cancel my card\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda2-py36]",
   "language": "python",
   "name": "conda-env-Anaconda2-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
