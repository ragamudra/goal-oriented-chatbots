{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JnDV5SgDEc15"
   },
   "source": [
    "# Code 5-38 to Code 5-51 and Code 5-65"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aeuAzb9-Ec17"
   },
   "source": [
    "This is a  “google colab” code. Please run this in google colab using  GPUs. Colaboratory (https://colab.research.google.com/notebooks/) is a Google research project created to help disseminate machine learning education and research. It's a Jupyter notebook environment that requires no setup to use and runs entirely in the cloud. You could get started and set up a “colab” jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3469,
     "status": "ok",
     "timestamp": 1597730297040,
     "user": {
      "displayName": "Mathangi Sri",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh0ldbF3y4-3F3Sow0eR6EEpQIkBrzVD03GQlAQlg=s64",
      "userId": "02610637757489513110"
     },
     "user_tz": -330
    },
    "id": "4XjRG7v5AlUp"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w8kC2SFnEc2A"
   },
   "source": [
    "Mounting the drive. Please make sure the files are in google drive before you mount the drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3455,
     "status": "ok",
     "timestamp": 1597730297042,
     "user": {
      "displayName": "Mathangi Sri",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh0ldbF3y4-3F3Sow0eR6EEpQIkBrzVD03GQlAQlg=s64",
      "userId": "02610637757489513110"
     },
     "user_tz": -330
    },
    "id": "btPFsnOVP_E0",
    "outputId": "c76e1d1e-fce2-40e4-8c8e-e42d7396eaab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jDh50e85Ec2H"
   },
   "source": [
    "Getting the files prepared in 2_Letsgo_preprocess\n",
    "1. Template file - dict_templ.pkl\n",
    "2. Preprocessed file for training - lets_go_model_set1.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3436,
     "status": "ok",
     "timestamp": 1597730297043,
     "user": {
      "displayName": "Mathangi Sri",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh0ldbF3y4-3F3Sow0eR6EEpQIkBrzVD03GQlAQlg=s64",
      "userId": "02610637757489513110"
     },
     "user_tz": -330
    },
    "id": "T-exI6Q8En4E"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "root_dir = \"/content/drive/My Drive/Newbounty_resync/Apress/Chapters/Chapter5\"\n",
    "base_fl = root_dir + '/dict_templ.pkl'\n",
    "pkl_file = open(base_fl, 'rb')\n",
    "df_sents = pickle.load(pkl_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5157,
     "status": "ok",
     "timestamp": 1597730298770,
     "user": {
      "displayName": "Mathangi Sri",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh0ldbF3y4-3F3Sow0eR6EEpQIkBrzVD03GQlAQlg=s64",
      "userId": "02610637757489513110"
     },
     "user_tz": -330
    },
    "id": "yWaQHCq1AlWd"
   },
   "outputs": [],
   "source": [
    "base_fl_csv =  root_dir + '/lets_go_model_set1.csv'\n",
    "t1 = pd.read_csv(base_fl_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5145,
     "status": "ok",
     "timestamp": 1597730298771,
     "user": {
      "displayName": "Mathangi Sri",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh0ldbF3y4-3F3Sow0eR6EEpQIkBrzVD03GQlAQlg=s64",
      "userId": "02610637757489513110"
     },
     "user_tz": -330
    },
    "id": "0frfECQlP9xH",
    "outputId": "a9ea7f73-2226-4720-bd37-5e8371052786"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>user_id</th>\n",
       "      <th>corrected_cust</th>\n",
       "      <th>corrected_bot1_shift</th>\n",
       "      <th>bots_templ_list_shift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2061123000</td>\n",
       "      <td>place_name  at  place_name  time is it is the...</td>\n",
       "      <td>leaving from  placename    sep_sent is this co...</td>\n",
       "      <td>templ_473 templ_1190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2061123000</td>\n",
       "      <td>place_name</td>\n",
       "      <td>leaving from  placename    sep_sent is this co...</td>\n",
       "      <td>templ_473 templ_1190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2061123000</td>\n",
       "      <td>yes</td>\n",
       "      <td>leaving from  placename    sep_sent is this co...</td>\n",
       "      <td>templ_473 templ_1190 templ_211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2061123000</td>\n",
       "      <td>place_name   place_name  of num_th  place_name</td>\n",
       "      <td>going to numth  placename    sep_sent is this ...</td>\n",
       "      <td>templ_902 templ_1190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2061123000</td>\n",
       "      <td>yes</td>\n",
       "      <td>going to numth  placename    sep_sent is this ...</td>\n",
       "      <td>templ_902 templ_1190 templ_1055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  ...             bots_templ_list_shift\n",
       "0           0  ...              templ_473 templ_1190\n",
       "1           1  ...              templ_473 templ_1190\n",
       "2           2  ...    templ_473 templ_1190 templ_211\n",
       "3           3  ...              templ_902 templ_1190\n",
       "4           4  ...   templ_902 templ_1190 templ_1055\n",
       "\n",
       "[5 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q_HDbGDxEc2U"
   },
   "source": [
    "We are adding “start” and “end” tags to the sentences. This is done to introduce the lag in the decoder architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5141,
     "status": "ok",
     "timestamp": 1597730298772,
     "user": {
      "displayName": "Mathangi Sri",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh0ldbF3y4-3F3Sow0eR6EEpQIkBrzVD03GQlAQlg=s64",
      "userId": "02610637757489513110"
     },
     "user_tz": -330
    },
    "id": "huvP7RW0AlWl"
   },
   "outputs": [],
   "source": [
    "t1[\"bots_templ_list_shift\"]  = 'start ' + t1[\"bots_templ_list_shift\"] + ' end'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z5rWH4IDEc2a"
   },
   "source": [
    "We are creating tokenizers one for encoder and for decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5125,
     "status": "ok",
     "timestamp": 1597730298773,
     "user": {
      "displayName": "Mathangi Sri",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh0ldbF3y4-3F3Sow0eR6EEpQIkBrzVD03GQlAQlg=s64",
      "userId": "02610637757489513110"
     },
     "user_tz": -330
    },
    "id": "4BWcFQ6jAlXi"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer1 = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5123,
     "status": "ok",
     "timestamp": 1597730298776,
     "user": {
      "displayName": "Mathangi Sri",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh0ldbF3y4-3F3Sow0eR6EEpQIkBrzVD03GQlAQlg=s64",
      "userId": "02610637757489513110"
     },
     "user_tz": -330
    },
    "id": "D5R8iUkuAlYn"
   },
   "outputs": [],
   "source": [
    "en_col_tr = list(t1[\"corrected_cust\"].str.split())\n",
    "de_col_tr = list(t1[\"bots_templ_list_shift\"].str.split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5107,
     "status": "ok",
     "timestamp": 1597730298777,
     "user": {
      "displayName": "Mathangi Sri",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh0ldbF3y4-3F3Sow0eR6EEpQIkBrzVD03GQlAQlg=s64",
      "userId": "02610637757489513110"
     },
     "user_tz": -330
    },
    "id": "kOun-5WQAlYv",
    "outputId": "505df90f-bd70-4553-8f27-6dd9f6cc62da"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['start', 'templ_473', 'templ_1190', 'end']"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "de_col_tr[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FPmaMar1Ec2o"
   },
   "source": [
    "We will now tokenize the sentences in customer and bot text (encoder input and decoder input respectively) and pad them based on max length of sentences in the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5103,
     "status": "ok",
     "timestamp": 1597730298778,
     "user": {
      "displayName": "Mathangi Sri",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh0ldbF3y4-3F3Sow0eR6EEpQIkBrzVD03GQlAQlg=s64",
      "userId": "02610637757489513110"
     },
     "user_tz": -330
    },
    "id": "8e-o9KNaAlZJ"
   },
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(en_col_tr)\n",
    "en_tr1 = tokenizer.texts_to_sequences(en_col_tr)\n",
    "tokenizer1.fit_on_texts(de_col_tr)\n",
    "de_tr1 = tokenizer1.texts_to_sequences(de_col_tr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5097,
     "status": "ok",
     "timestamp": 1597730298779,
     "user": {
      "displayName": "Mathangi Sri",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh0ldbF3y4-3F3Sow0eR6EEpQIkBrzVD03GQlAQlg=s64",
      "userId": "02610637757489513110"
     },
     "user_tz": -330
    },
    "id": "ZA-w2iLEAlZd"
   },
   "outputs": [],
   "source": [
    "def get_max_len(list1):\n",
    "    len_list = [len(i) for i in list1]\n",
    "    return max(len_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5081,
     "status": "ok",
     "timestamp": 1597730298779,
     "user": {
      "displayName": "Mathangi Sri",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh0ldbF3y4-3F3Sow0eR6EEpQIkBrzVD03GQlAQlg=s64",
      "userId": "02610637757489513110"
     },
     "user_tz": -330
    },
    "id": "09ewxv2XAlZt",
    "outputId": "5f912b83-e86f-44c2-e4e1-ef5b18f7cc55"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7760, 27), (7760, 28), 28, 27)"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len1 = get_max_len(en_tr1)\n",
    "max_len2 = get_max_len(de_tr1)\n",
    "\n",
    "en_tr2 = pad_sequences(en_tr1, maxlen=max_len1, dtype='int32', padding='post')\n",
    "de_tr2 = pad_sequences(de_tr1, maxlen=max_len2, dtype='int32', padding='post')\n",
    "de_tr2.shape,en_tr2.shape,max_len1,max_len2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BT8E5aExEc25"
   },
   "source": [
    "We can see that encoder and decoder input have 2 dimensional shapes. Since we are directly feeding them to LSTM (without embedding layer) we need to convert them into 3 dimensional arrays. This is done by converting the sequence of words to one hot encoded forms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5061,
     "status": "ok",
     "timestamp": 1597730298780,
     "user": {
      "displayName": "Mathangi Sri",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh0ldbF3y4-3F3Sow0eR6EEpQIkBrzVD03GQlAQlg=s64",
      "userId": "02610637757489513110"
     },
     "user_tz": -330
    },
    "id": "Rr5FUy6hAlbb",
    "outputId": "5e65f6aa-c6c4-4ca8-9944-be1001110284"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7760, 28, 733), (7760, 27, 1506))"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "en_tr3 = to_categorical(en_tr2)\n",
    "de_tr3 = to_categorical(de_tr2)\n",
    "en_tr3.shape, de_tr3.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BnutjVlPEc2-"
   },
   "source": [
    "The arrays are now 3-dimensional. Please note that so far we have only inputs defined. We have to now define the outputs. The output of the model is the decoder with a t +1 timstep. We want to predict given the last word the next word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5598,
     "status": "ok",
     "timestamp": 1597730299321,
     "user": {
      "displayName": "Mathangi Sri",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh0ldbF3y4-3F3Sow0eR6EEpQIkBrzVD03GQlAQlg=s64",
      "userId": "02610637757489513110"
     },
     "user_tz": -330
    },
    "id": "UyzDNuoYAlcX"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.ndimage.interpolation import shift\n",
    "de_target3 = np.roll(de_tr3, -1,axis=1)\n",
    "de_target3[:,-1,:]=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xHsOKtHREc3C"
   },
   "source": [
    "Saving number of encoder and decoder tokens to define model inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5596,
     "status": "ok",
     "timestamp": 1597730299324,
     "user": {
      "displayName": "Mathangi Sri",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh0ldbF3y4-3F3Sow0eR6EEpQIkBrzVD03GQlAQlg=s64",
      "userId": "02610637757489513110"
     },
     "user_tz": -330
    },
    "id": "KtpJZJ8UAlcy"
   },
   "outputs": [],
   "source": [
    "num_encoder_tokens = en_tr3.shape[2]\n",
    "num_decoder_tokens = de_tr3.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5582,
     "status": "ok",
     "timestamp": 1597730299326,
     "user": {
      "displayName": "Mathangi Sri",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh0ldbF3y4-3F3Sow0eR6EEpQIkBrzVD03GQlAQlg=s64",
      "userId": "02610637757489513110"
     },
     "user_tz": -330
    },
    "id": "sxukZp2O2Vc4",
    "outputId": "5cacd7a4-1e9e-407d-d49c-e3be6405cb98"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 1506, 733)"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len1,num_decoder_tokens,num_encoder_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5570,
     "status": "ok",
     "timestamp": 1597730299329,
     "user": {
      "displayName": "Mathangi Sri",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh0ldbF3y4-3F3Sow0eR6EEpQIkBrzVD03GQlAQlg=s64",
      "userId": "02610637757489513110"
     },
     "user_tz": -330
    },
    "id": "uM6EqNxCjkkc",
    "outputId": "cbcbb02f-080c-4667-8aec-aa573fcf7730"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(733, 1506, 733)"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_encoder_tokens,num_decoder_tokens,en_tr3.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11310,
     "status": "ok",
     "timestamp": 1597730305083,
     "user": {
      "displayName": "Mathangi Sri",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh0ldbF3y4-3F3Sow0eR6EEpQIkBrzVD03GQlAQlg=s64",
      "userId": "02610637757489513110"
     },
     "user_tz": -330
    },
    "id": "kW-CTvflHviN",
    "outputId": "9024e20a-2fbe-4baf-94c5-4affbc000bae"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.test.gpu_device_name()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K7ECAqijEc3S"
   },
   "source": [
    "In the encoder - decoder architecture with teacher forcing there is a difference between the training and inferencing steps.The code is derived from this article https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html . First we see the steps for training. Here we are defining LSTMs with 100 hidden nodes for each step of the encoder-input (customer text). We keep the final cell state and the hidden state of the encoder and discard the outputs from each of the LSTM cells. Decoder takes input from the bot text and initializes the initial state from the encoder output. Since the encoder has 100 hidden nodes so does the decoder also has 100 hidden nodes. The output of decoder at each cell is passed to a dense layer. The network is trained with the  time adjusted of “decoder input”. Basically encoder values and decoder inputs at t-1 predicting the bot text at t."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13028,
     "status": "ok",
     "timestamp": 1597730306807,
     "user": {
      "displayName": "Mathangi Sri",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh0ldbF3y4-3F3Sow0eR6EEpQIkBrzVD03GQlAQlg=s64",
      "userId": "02610637757489513110"
     },
     "user_tz": -330
    },
    "id": "vD_6RGnmLMsT"
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "encoder = LSTM(100, dropout=.2,return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "\n",
    "decoder_lstm = LSTM(100, return_sequences=True, return_state=True,dropout=0.2)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v_Gk04xxEc3X"
   },
   "source": [
    "We will now see the set up for model inference.\n",
    "\n",
    "Encoder Output\n",
    "First we prepare a layer to get the encoder states. These are the initial states for the decoder\n",
    "\n",
    "Decoder Input\n",
    "The decoder input is not known when the model runs. Hence we will have to use the architecture to predict one word at a time and use that word to predict the next word. The decoder part of the model takes the decoder (time delayed input). For the “first” word the decoder model is initialized with encoder states. “decoder_lstm layer” is called using decoder inputs and the initialized encoder states.This layer provides 2 sets of outputs. The output set of the cells (decoder_ouput) and the final output of cell_state and hidden_state. The “decoder_ouput”” is passed to the dense layer to get the final prediction of the bot text. The decoder states output is used to update states for the next run (next word prediction). The bot_text is appended to the the decoder input and the same process is repeated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13025,
     "status": "ok",
     "timestamp": 1597730306809,
     "user": {
      "displayName": "Mathangi Sri",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh0ldbF3y4-3F3Sow0eR6EEpQIkBrzVD03GQlAQlg=s64",
      "userId": "02610637757489513110"
     },
     "user_tz": -330
    },
    "id": "zFHWh72pEc3X"
   },
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(100,))\n",
    "decoder_state_input_c = Input(shape=(100,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0z6MSnUEEc3b"
   },
   "source": [
    "we will be training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 106805,
     "status": "ok",
     "timestamp": 1597730426783,
     "user": {
      "displayName": "Mathangi Sri",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh0ldbF3y4-3F3Sow0eR6EEpQIkBrzVD03GQlAQlg=s64",
      "userId": "02610637757489513110"
     },
     "user_tz": -330
    },
    "id": "26rrTJIyAlgi",
    "outputId": "d44b7347-f7ae-41e8-ea57-c3f098fe54fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "207/207 [==============================] - 4s 18ms/step - loss: 0.9829 - val_loss: 0.6339\n",
      "Epoch 2/30\n",
      "207/207 [==============================] - 3s 15ms/step - loss: 0.5339 - val_loss: 0.5465\n",
      "Epoch 3/30\n",
      "207/207 [==============================] - 3s 16ms/step - loss: 0.4654 - val_loss: 0.4992\n",
      "Epoch 4/30\n",
      "207/207 [==============================] - 3s 15ms/step - loss: 0.4266 - val_loss: 0.4667\n",
      "Epoch 5/30\n",
      "207/207 [==============================] - 3s 16ms/step - loss: 0.3995 - val_loss: 0.4503\n",
      "Epoch 6/30\n",
      "207/207 [==============================] - 3s 15ms/step - loss: 0.3838 - val_loss: 0.4390\n",
      "Epoch 7/30\n",
      "207/207 [==============================] - 3s 15ms/step - loss: 0.3696 - val_loss: 0.4268\n",
      "Epoch 8/30\n",
      "207/207 [==============================] - 3s 16ms/step - loss: 0.3587 - val_loss: 0.4209\n",
      "Epoch 9/30\n",
      "207/207 [==============================] - 3s 15ms/step - loss: 0.3525 - val_loss: 0.4121\n",
      "Epoch 10/30\n",
      "207/207 [==============================] - 3s 15ms/step - loss: 0.3444 - val_loss: 0.4094\n",
      "Epoch 11/30\n",
      "207/207 [==============================] - 3s 16ms/step - loss: 0.3372 - val_loss: 0.4038\n",
      "Epoch 12/30\n",
      "207/207 [==============================] - 3s 15ms/step - loss: 0.3320 - val_loss: 0.4030\n",
      "Epoch 13/30\n",
      "207/207 [==============================] - 3s 15ms/step - loss: 0.3270 - val_loss: 0.4003\n",
      "Epoch 14/30\n",
      "207/207 [==============================] - 3s 15ms/step - loss: 0.3243 - val_loss: 0.3990\n",
      "Epoch 15/30\n",
      "207/207 [==============================] - 3s 15ms/step - loss: 0.3206 - val_loss: 0.3976\n",
      "Epoch 16/30\n",
      "207/207 [==============================] - 3s 15ms/step - loss: 0.3183 - val_loss: 0.3986\n",
      "Epoch 17/30\n",
      "207/207 [==============================] - 3s 15ms/step - loss: 0.3137 - val_loss: 0.3935\n",
      "Epoch 18/30\n",
      "207/207 [==============================] - 3s 16ms/step - loss: 0.3114 - val_loss: 0.3925\n",
      "Epoch 19/30\n",
      "207/207 [==============================] - 3s 16ms/step - loss: 0.3088 - val_loss: 0.3914\n",
      "Epoch 20/30\n",
      "207/207 [==============================] - 3s 15ms/step - loss: 0.3069 - val_loss: 0.3925\n",
      "Epoch 21/30\n",
      "207/207 [==============================] - 3s 16ms/step - loss: 0.3037 - val_loss: 0.3893\n",
      "Epoch 22/30\n",
      "207/207 [==============================] - 3s 16ms/step - loss: 0.3023 - val_loss: 0.3926\n",
      "Epoch 23/30\n",
      "207/207 [==============================] - 3s 16ms/step - loss: 0.3001 - val_loss: 0.3927\n",
      "Epoch 24/30\n",
      "207/207 [==============================] - 3s 15ms/step - loss: 0.2999 - val_loss: 0.3952\n",
      "Epoch 25/30\n",
      "207/207 [==============================] - 3s 15ms/step - loss: 0.2981 - val_loss: 0.3932\n",
      "Epoch 26/30\n",
      "207/207 [==============================] - 3s 15ms/step - loss: 0.2969 - val_loss: 0.3991\n",
      "Epoch 27/30\n",
      "207/207 [==============================] - 3s 15ms/step - loss: 0.2949 - val_loss: 0.3917\n",
      "Epoch 28/30\n",
      "207/207 [==============================] - 3s 15ms/step - loss: 0.2956 - val_loss: 0.3896\n",
      "Epoch 29/30\n",
      "207/207 [==============================] - 3s 15ms/step - loss: 0.2930 - val_loss: 0.3952\n",
      "Epoch 30/30\n",
      "207/207 [==============================] - 3s 15ms/step - loss: 0.2910 - val_loss: 0.3868\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb4f82c4cc0>"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "fp = root_dir + \"/models/best_collab_model.h5\"\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=2),\n",
    "             ModelCheckpoint(filepath=fp, monitor='val_loss', save_best_only=True)]\n",
    "\n",
    "#Adam(lr=0.001)\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "model.fit([en_tr3, de_tr3], de_target3,\n",
    "          batch_size=30,\n",
    "          epochs=30,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UzPrBZGtEc3g"
   },
   "source": [
    "We now want to test if the model works. So we save the model objects. Use relevant “root_dir” folder here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ukwzXH-KnOcY"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import save_model\n",
    "dest_folder = root_dir + '/collab_models/'\n",
    "encoder_model.save( dest_folder + 'enc_model_collab_211_redo')\n",
    "decoder_model.save( dest_folder + 'dec_model_collab_211_redo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jVDw025CnZgm"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "dest_folder = root_dir + '/collab_models/'\n",
    "output = open(dest_folder + 'tokenizer_en_redo_1.pkl', 'wb')\n",
    "\n",
    "# Pickle dictionary using protocol 0.\n",
    "pickle.dump(tokenizer, output)\n",
    "\n",
    "dest_folder = root_dir + '/collab_models/'\n",
    "output1 = open(dest_folder + 'tokenizer_de_redo.pkl', 'wb')\n",
    "pickle.dump(tokenizer1, output1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iktE3pc9Ec3s"
   },
   "source": [
    "# This is a differnt section on using Bi-direc LSTM instead of LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZdktQj4mEc3t"
   },
   "source": [
    "Bi-directional LSTM - Encoder and Decoder Model creation could be replaced with the below code for bidrectional LSTMS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SrJ9ZX7oEc3u"
   },
   "source": [
    "Encoder\n",
    "Bidirectional LSTMs have additional outputs of forward and backward hidden states (forward_h, forward_c, backward_h, backward_c). These are then concatenated (hidden states together and cell states together) to get the final encoder states.\n",
    "\n",
    "Decoder: \n",
    "Decoder has unidirectional LSTM as with our earlier case. However the number of hidden units is equal to the concatenated hidden units of bidirectional LSTM of the encoder. In our case, encoder LSTMs have 100 each and decoder has 200 units.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "atoDfD7BEc3v"
   },
   "outputs": [],
   "source": [
    "from keras.layers import LSTM,Bidirectional,Input,Concatenate\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "\n",
    "\n",
    "n_units = 100\n",
    "n_input = num_encoder_tokens\n",
    "n_output = num_decoder_tokens\n",
    "\n",
    "# encoder\n",
    "encoder_inputs = Input(shape=(None, n_input))\n",
    "encoder = Bidirectional(LSTM(n_units, return_state=True))\n",
    "encoder_outputs, forward_h, forward_c, backward_h, backward_c = encoder(encoder_inputs)\n",
    "state_h = Concatenate()([forward_h, backward_h])\n",
    "state_c = Concatenate()([forward_c, backward_c])\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# decoder\n",
    "decoder_inputs = Input(shape=(None, n_output))    \n",
    "decoder_lstm = LSTM(n_units*2, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "decoder_dense = Dense(n_output, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "\n",
    "# define inference encoder\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "# define inference decoder\n",
    "decoder_state_input_h = Input(shape=(n_units*2,))\n",
    "decoder_state_input_c = Input(shape=(n_units*2,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "3_Encode_Decode_letsgo_bidirec_collab_v2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda2-py36]",
   "language": "python",
   "name": "conda-env-Anaconda2-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
