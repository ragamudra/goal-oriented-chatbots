{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code 5-52 to Code 5-64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel\\parentpoller.py:116: UserWarning: Parent poll failed.  If the frontend dies,\n",
      "                the kernel may be left running.  Please let us know\n",
      "                about your system (bitness, Python, etc.) at\n",
      "                ipython-dev@scipy.org\n",
      "  ipython-dev@scipy.org\"\"\")\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is written in local and we bring the files from “google colab”. The code would have 3 parts - once a text is given the preprocessing (replacing appropriate words and regular expressions), the conversion to text to the required array format and the model inferring\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load we generated files from 3_Encode_Decode_letsgo_bidirec_collab_v2\n",
    "1. Encoder and Decoder model files\n",
    "2. encoder and decoder pickle files\n",
    "3. Templates dictionary files\n",
    "4. bus_stops pickle file for preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###use your folder here\n",
    "dest_folder = 'collab_models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\Anaconda2\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\user\\Anaconda2\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:4010: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "encoder_model = load_model(dest_folder + 'enc_model_collab_211_redo1')\n",
    "decoder_model = load_model(dest_folder +'dec_model_collab_211_redo1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "pkl_file = open(dest_folder + 'tokenizer_en_redo_1.pkl', 'rb')\n",
    "\n",
    "tokenizer = pickle.load(pkl_file)\n",
    "\n",
    "\n",
    "pkl_file = open(dest_folder + 'tokenizer_de_redo.pkl', 'rb')\n",
    "\n",
    "tokenizer1 = pickle.load(pkl_file)\n",
    "\n",
    "pkl_file = open( 'dict_templ.pkl', 'rb')\n",
    "\n",
    "df_sents = pickle.load(pkl_file)\n",
    "\n",
    "\n",
    "bus_sch = np.load(\"bus_stops.npz\",allow_pickle=True) #make sure you use the .npz!\n",
    "bus_sch1 = list(bus_sch['arr_0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a repeat of the process we followed in 2_Letsgo_preprocess.ipynb while training - replacing place name, replacing direction, number names, bus name, times and special characters. This gets applied to customer sentence and then fed into model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda2\\envs\\py36\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "from fuzzywuzzy import fuzz \n",
    "import re\n",
    "def repl_place_bus(ctext):\n",
    "    #for i,row in t2.iterrows():\n",
    "    #ctext = row[req_col]\n",
    "    fg=0\n",
    "    str1=ctext\n",
    "\n",
    "    for j in ctext.split():\n",
    "        #print (j)\n",
    "\n",
    "        for k in bus_sch1:\n",
    "            score = fuzz.ratio(j,k )\n",
    "            if(score>=70):\n",
    "                #print (i,j,k)\n",
    "                fg=1\n",
    "                break;\n",
    "        #if(fg==1):\n",
    "            #break;\n",
    "        if(fg==1):\n",
    "            fg=0\n",
    "            str1 = str1.replace(j,\" place_name \")\n",
    "\n",
    "    return str1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "direct_list = ['east','west','north','south']\n",
    "def am_pm_direct_repl(ctext):\n",
    "    ctext = re.sub('p.m','pm',ctext)\n",
    "    ctext = re.sub('p m','pm',ctext)\n",
    "    ctext = re.sub('a.m','am',ctext)\n",
    "    ctext = re.sub('a m','am',ctext)\n",
    "\n",
    "    for i in direct_list:\n",
    "        ctext = re.sub(i,' direction ',ctext)\n",
    "   \n",
    "    return ctext\n",
    "\n",
    "from num2words import num2words\n",
    "word_num_list = []\n",
    "word_num_th_list = []\n",
    "for i in range(0,100):\n",
    "    word_num_list.append(num2words(i))\n",
    "    word_num_th_list.append(num2words(i,to='ordinal'))\n",
    "    \n",
    "def repl_num_words(ctext):\n",
    "    for num,i in enumerate(word_num_th_list):\n",
    "        ctext = re.sub(i,\"num_th\",ctext)\n",
    "        ctext = re.sub(word_num_list[num],str(num),ctext)\n",
    "    return ctext\n",
    "\n",
    "\n",
    "def preprocces(ctext):\n",
    "    ctext = ctext.lower()\n",
    "    ctext1 = repl_place_bus(ctext)\n",
    "    ctext1 = am_pm_direct_repl(ctext1)\n",
    "    ctext1 = repl_num_words(ctext1)\n",
    "\n",
    "\n",
    "    ctext1 = re.sub('[0-9]{1,2}[a-z]{1,2}','bus_name',ctext1)\n",
    "    ctext1 = re.sub('[0-9]{1,2}[\\.\\s]*[0-9]{1,2}[\\s]*pm','time_name',ctext1)\n",
    "    ctext1 = re.sub('[0-9]{1,2}[\\.\\s]*[0-9]{1,2}[\\s]*am','time_name',ctext1)\n",
    "\n",
    "    ctext1 =re.sub('(\\.\\s){1,3}',' ',ctext1)\n",
    "    ctext1 =re.sub('(\\.){1,3}',' ',ctext1)\n",
    "    \n",
    "    return ctext1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples of preprocess functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bus_name'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sent = \"when is the next bus to crafton boulevard 9 00 P.M east. . 85c\"\n",
    "sent = \"54c\"\n",
    "preprocces(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now set to convert the preprocessed into the right array of numbers as defined during training using tokenizer objects. We set padding length and number of classes for one-hot from the values in training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len1 = 28\n",
    "num_encoder_tokens =733\n",
    "num_decoder_tokens = 1506\n",
    "shp = 733"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_sent(sent,shp):\n",
    "    sent = preprocces(sent)\n",
    "    #print (sent)\n",
    "    en_col_tr = [sent.split()]\n",
    "    \n",
    "    en_tr1= tokenizer.texts_to_sequences(en_col_tr )\n",
    "    \n",
    "    en_tr2 = pad_sequences(en_tr1, maxlen=max_len1, dtype='int32', padding='post')\n",
    "    en_tr3 = to_categorical(en_tr2,num_classes =shp)\n",
    "    \n",
    "    return en_tr3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We check using our test preprocessed sentence and see if the shape is as expected (rows* length of sequence * one-hot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28, 733)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent1 = 'when is the next bus to crafton  place_name  time_name  direction  bus_name'\n",
    "sent1_conv = conv_sent(sent1,num_encoder_tokens)\n",
    "sent1_conv.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to apply the model to the converted sentences.The first word will be initialised to ‘start’ token and states of the decoder to be initialized to encoder states. With that we get the next word. Now with the next word and the states of the word as the set of inputs we get the word at t+1. We repeat the process till we reach the ‘end’ token. Remember we trained on bot sentence templates and not on the actual sentences. Hence we get the template id as the output. We then convert the template id to the required word using \"rev_dict\" function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rev_dict(req_word):\n",
    "    str1=\"\"\n",
    "    for k,v in df_sents.items():\n",
    "        if(df_sents[k]==[req_word]):\n",
    "            str1 = k\n",
    "    return str1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "def get_op(text1,shp):\n",
    "\n",
    "    st_pos = 0\n",
    "    input_seq = conv_sent(text1, shp)\n",
    "    #print (input_seq)\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    str_all = \"\"\n",
    "    # Populate the first word of target sequence with the start word.\n",
    "    target_seq[0, 0, st_pos] = 1\n",
    "    for i in range(0,10):\n",
    "        decoded_sentence = ''\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "                [target_seq] + states_value)\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "           \n",
    "        sampled_char = tokenizer1.sequences_to_texts([[sampled_token_index]])\n",
    "        str1 = rev_dict(sampled_char[0])\n",
    "        str_all = str_all + \"\\n\" + str1\n",
    "        \n",
    "        if(sampled_char[0]=='end'):\n",
    "            break;\n",
    "        else:\n",
    "            decoded_sentence += sampled_char[0]\n",
    "            target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "            target_seq[0, 0, sampled_token_index] = 1.\n",
    "            ####initializing state values\n",
    "            states_value = [h, c]\n",
    "            \n",
    "    return str_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outputs from the bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n  placename  going to  placename  transportation center   \\n short_num  short_num n short_num where are you leaving from  \\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = \"54c\"\n",
    "get_op(text1,num_encoder_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n did i get that  placename okaywhere would you like to leave from  \\n if you  placename  to leave from  placename  and bausman say yes or press  short_num  otherwise say no or press  short_num   \\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = \"next bus to boulevard\"\n",
    "get_op(text1,shp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n when would you like to travel  \\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = \"Do you have bus to downtown in the morning\"\n",
    "get_op(text1,shp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We seem to have a start here. Following can be done to improve the responses\n",
    "\n",
    "1.\tWe need to replace the answers with the appropriate place names and present a more meaningful answer. \n",
    "2.\tWe have trained on a single input. But its a conversation so we need to train it on the n-1 response and the question to get the next response\n",
    "3.\tSome of the transcription were not accurate, if it can be weeded out and model trained with a cleaner corpus\n",
    "4.\tUsing embeddings (pre-trained or trained during the model) as input to LSTMs\n",
    "5.\tTuning hyperparameters like learning rates or learning algorithms\n",
    "6.\tStacked LSTM layers (First set of LSTMs provide inputs to the second set of LSTMs)\n",
    "7.\tUsing Bidirectional LSTMs. Lets see an example of bidirectional lstm\n",
    "8.\tAdvanced architectures like ‘BERT’\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda2-py36]",
   "language": "python",
   "name": "conda-env-Anaconda2-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
